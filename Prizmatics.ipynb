{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
    "X = np.concatenate((X_train, X_test), axis=0)#putting all sentences together\n",
    "y = np.concatenate((y_train, y_test), axis=0)#putting all labels together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "(50000,)\n",
      "(50000,)\n",
      "214\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "# Shape of data\n",
    "print(\"Training data: \")\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(len(X[90]))#shows that there are 214 words in this paticular review\n",
    "print(len(X[10]))#450 words are there in this review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Summarize number of classes\n",
    "print(\"Classes: \")\n",
    "print(np.unique(y))\n",
    "# i.e Binary Classification(positive and negative review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: \n",
      "88585\n"
     ]
    }
   ],
   "source": [
    "# Summarize number of unique words in whole dataset using X\n",
    "print(\"Number of words: \")\n",
    "#print(len(np.unique(np.hstack(X[1]))))\n",
    "#X[1]\n",
    "#np.hstack(X[1])\n",
    "print(len(np.unique(np.hstack(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 234.76 words (172.911495)\n"
     ]
    }
   ],
   "source": [
    "# Summarize review length of each sentence using X[i]\n",
    "print(\"Review length: \")\n",
    "result = [len(x) for x in X]\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))\n",
    "#std to check for distribution\n",
    "#mean to calculate the average length of a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert positive integer representations of words into \n",
    "#a word embedding by an Embedding layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "top_words = 5000 # selecting only top frequent words and zero the rest\n",
    "max_words = 500  # review length is set\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)# making length of each review equal\n",
    "#len(X_train[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               4000250   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Multi layer Perceptron Model the model\n",
    "model = Sequential() # a layer model\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      " - 55s - loss: 4.0720e-04 - acc: 1.0000 - val_loss: 0.6209 - val_acc: 0.8635\n",
      "Epoch 2/3\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=128, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
